{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\junaid\\AppData\\Local\\Temp/ipykernel_18168/2909815236.py:171: RuntimeWarning: invalid value encountered in log\n",
      "  delta*I*D+alpha2*np.log(1+Q)]\n",
      "c:\\Users\\junaid\\anaconda3\\lib\\site-packages\\scipy\\integrate\\odepack.py:247: ODEintWarning: Excess accuracy requested (tolerances too small). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "c:\\Users\\junaid\\anaconda3\\lib\\site-packages\\scipy\\integrate\\odepack.py:247: ODEintWarning: Excess accuracy requested (tolerances too small). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "C:\\Users\\junaid\\AppData\\Local\\Temp/ipykernel_18168/2909815236.py:171: RuntimeWarning: overflow encountered in double_scalars\n",
      "  delta*I*D+alpha2*np.log(1+Q)]\n",
      "C:\\Users\\junaid\\AppData\\Local\\Temp/ipykernel_18168/2909815236.py:168: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  zeta*(N-S)-beta1*(to-t)*I-beta2*I-Keta-delta*I,\n",
      "C:\\Users\\junaid\\AppData\\Local\\Temp/ipykernel_18168/2909815236.py:171: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  delta*I*D+alpha2*np.log(1+Q)]\n",
      "c:\\Users\\junaid\\anaconda3\\lib\\site-packages\\scipy\\integrate\\odepack.py:247: ODEintWarning: Excess accuracy requested (tolerances too small). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.interpolate import CubicSpline\n",
    "import keras.backend as K\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "\n",
    "\n",
    "Normy=1\n",
    "state_dat_est=[]\n",
    "state_dat_ref=[]\n",
    "par_dat_est=[]\n",
    "num_parameters=9\n",
    "sampling_fact=30;  # defining factor\n",
    "Fs=sampling_fact\n",
    "Keta=0\n",
    "horizon=173\n",
    "\n",
    "\n",
    "\n",
    "trans='approximator9.h5'\n",
    "deformy='deformer4.h5'\n",
    "\n",
    "my_model_p = keras.models.load_model(trans)\n",
    "my_model = keras.models.load_model(deformy)\n",
    "\n",
    "\n",
    "for i in range(horizon):\n",
    "    # Get States Data\n",
    "    X_Dat=[]\n",
    "    daty = genfromtxt(\"D:\\Research_work\\covid_parameters_2\\dataset_gen\\input\\states_ \"+str(i)+\" .csv\", delimiter=',')\n",
    "    days=daty[:,0]\n",
    "    S=daty[:,1]\n",
    "    I=daty[:,2]\n",
    "    Q=daty[:,3]\n",
    "    R=daty[:,4]\n",
    "    D=daty[:,5]\n",
    "    \n",
    "\n",
    "    # if i==0:\n",
    "    init_cond=[S[0],I[0],Q[0],R[0],D[0]]\n",
    "    # else:\n",
    "    #     temp_s=state_dat_est[len(state_dat_est)-1]\n",
    "        \n",
    "    #     init_cond=[temp_s[2,0],temp_s[2,1],temp_s[2,2],temp_s[2,3],temp_s[2,4]]\n",
    "\n",
    "    S_ref=S\n",
    "    I_ref=I\n",
    "    Q_ref=Q\n",
    "    R_ref=R\n",
    "    D_ref=D\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    days_n=np.linspace(0,days[len(days)-1],len(days)*sampling_fact)\n",
    "\n",
    "    c_S = CubicSpline(days,S)\n",
    "    cubic_S=c_S(days_n)\n",
    "\n",
    "    c_I = CubicSpline(days,I)\n",
    "    cubic_I=c_I(days_n)\n",
    "\n",
    "    c_Q = CubicSpline(days,Q)\n",
    "    cubic_Q=c_Q(days_n)\n",
    "\n",
    "    c_R = CubicSpline(days,D)\n",
    "    cubic_R=c_R(days_n)\n",
    "\n",
    "    c_D = CubicSpline(days,D)\n",
    "    cubic_D=c_D(days_n)\n",
    "\n",
    "\n",
    "    cubic_S=cubic_S[0:81]\n",
    "    cubic_I=cubic_I[0:81]\n",
    "    cubic_Q=cubic_Q[0:81]\n",
    "    cubic_R=cubic_R[0:81]\n",
    "    cubic_D=cubic_D[0:81]\n",
    "\n",
    "\n",
    "    nc=1\n",
    "    S = np.reshape(cubic_S, (-1, 9))\n",
    "    pca = PCA(n_components=nc)\n",
    "    S_new= pca.fit_transform(S).flatten()\n",
    "    S_new=np.expand_dims(S_new, axis=0)\n",
    "\n",
    "    I = np.reshape(cubic_I, (-1, 9))\n",
    "    pca = PCA(n_components=nc)\n",
    "    I_new= pca.fit_transform(I).flatten()\n",
    "    I_new=np.expand_dims(I_new, axis=0)\n",
    "    \n",
    "    Q= np.reshape(cubic_Q, (-1, 9))\n",
    "    pca = PCA(n_components=nc)\n",
    "    Q_new= pca.fit_transform(Q).flatten()\n",
    "    Q_new=np.expand_dims(Q_new, axis=0)\n",
    "\n",
    "    R= np.reshape(cubic_R, (-1, 9))\n",
    "    pca = PCA(n_components=nc)\n",
    "    R_new= pca.fit_transform(R).flatten() \n",
    "    R_new=np.expand_dims(R_new, axis=0)\n",
    "\n",
    "    D= np.reshape(cubic_D, (-1, 9))\n",
    "    pca = PCA(n_components=nc)\n",
    "    D_new= pca.fit_transform(D).flatten() \n",
    "    D_new=np.expand_dims(D_new, axis=0)\n",
    "\n",
    "    my_dat=np.concatenate((np.transpose(S_new),np.transpose(I_new),np.transpose(Q_new),np.transpose(R_new),np.transpose(D_new)),axis=1)\n",
    "    #----------------------------------------------------------------------------------------------------------------------\n",
    "    #----------------------------------------------------------------------------------------------------------------------\n",
    "    #Dimensions should be time x channels\n",
    "    X_Dat.append(my_dat)\n",
    "\n",
    "    X_datnew=np.asarray(X_Dat)\n",
    "\n",
    "    X=X_datnew\n",
    "\n",
    "    \n",
    "    out_p=my_model_p.predict(X)\n",
    "\n",
    "\n",
    "    out_p_new=np.expand_dims(out_p, axis=2)\n",
    "    \n",
    "    out=my_model.predict(out_p_new)\n",
    "\n",
    "    parameters=list(out[0])\n",
    "\n",
    "\n",
    "    #Hybrid SIQRD model\n",
    "    zeta=parameters[0]\n",
    "    beta1=parameters[1]\n",
    "    beta2=parameters[2]\n",
    "    alpha1=parameters[3]\n",
    "    alpha2=parameters[4]\n",
    "    delta=parameters[5]\n",
    "    Keta=parameters[6]\n",
    "    to=parameters[7]\n",
    "    gamma=parameters[8]\n",
    "\n",
    "\n",
    "\n",
    "    N=sum(init_cond)\n",
    "\n",
    "\n",
    "\n",
    "    def siqrd(states, t):\n",
    "\n",
    "        S=states[0]\n",
    "        I=states[1]\n",
    "        Q=states[2]\n",
    "        R=states[3]\n",
    "        D=states[4]\n",
    "\n",
    "\n",
    "        return [-zeta*(N-S)+gamma*R,\n",
    "        zeta*(N-S)-beta1*(to-t)*I-beta2*I-Keta-delta*I,\n",
    "        beta2*I+Keta-alpha2*Q-alpha1*Q,\n",
    "        beta1*(to-t)*I+alpha1*Q-gamma*R,\n",
    "        delta*I*D+alpha2*np.log(1+Q)]\n",
    "\n",
    "    Fs=10\n",
    "    days = np.linspace(0, 3, Fs*3)\n",
    "\n",
    "    SIQRD = odeint(siqrd,init_cond,days)\n",
    "    S= np.abs(SIQRD[::Fs,0])\n",
    "    I = np.abs(SIQRD[::Fs,1])\n",
    "    Q= np.abs(SIQRD[::Fs,2])\n",
    "    R = np.abs(SIQRD[::Fs,3])\n",
    "    D = np.abs(SIQRD[::Fs,4])\n",
    "    days=days[::Fs]\n",
    "\n",
    "    state_dater=np.stack((S,I,Q,R,D))\n",
    "    state_dater=np.transpose(state_dater)\n",
    "\n",
    "    state_rdater=np.stack((S_ref,I_ref,Q_ref,R_ref,D_ref))\n",
    "    state_rdater=np.transpose(state_rdater)\n",
    "\n",
    "    # para_dater=np.stack((alpha*np.ones(3),t1*np.ones(3),gamma1*np.ones(3),gamma2*np.ones(3),beta*np.ones(3)))\n",
    "    # para_dater=np.stack((alpha*np.ones(3),beta*np.ones(3),gamma1*np.ones(3),gamma2*np.ones(3),delta*np.ones(3)))\n",
    "    para_dater=np.stack((zeta*np.ones(3),beta1*np.ones(3),beta2*np.ones(3),alpha1*np.ones(3),alpha2*np.ones(3),delta*np.ones(3),Keta*np.ones(3),to*np.ones(3),gamma*np.ones(3)))\n",
    "    para_dater=np.transpose(para_dater)\n",
    "\n",
    "\n",
    "    state_dat_est.append(state_dater)\n",
    "    state_dat_ref.append(state_rdater)\n",
    "    par_dat_est.append(para_dater)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "state_dat_est=np.vstack(state_dat_est)   \n",
    "state_dat_ref=np.vstack(state_dat_ref)\n",
    "par_dat_est=np.vstack(par_dat_est)\n",
    "\n",
    "days=np.linspace(0,state_dat_est.shape[0]-1,state_dat_est.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('past_data_ref.csv', state_dat_ref, delimiter=',')\n",
    "np.savetxt('past_data_est.csv', state_dat_est, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "900319d10e44314f6b60bc90e5bd7346f614de9c8cac248c09f743c4d5156675"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
